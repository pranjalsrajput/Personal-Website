
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="css/buttons.css">
<link rel="stylesheet" href="css/style.css">

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</head>


    <title>Generalized Zero and Few-Shot Transfer for Facial Forgery Detection</title>
    <meta property="og:image" content="images/teaser.jpg">
    <meta property="og:title" content="Generalized Zero and Few-Shot Transfer for Facial Forgery Detection">
  

  <body>
        <br>
          <center>
            <span style="font-size:34px">Generalized Zero and Few-Shot Transfer for Facial Forgery Detection</span><br><br>

          <table align="center" width="80%">
            <tbody><tr>
                    <td align="center" width="25%">
              <center>
                <span style="font-size:20px"><a href="http://niessnerlab.org/members/shivangi_aneja/profile.html">Shivangi Aneja</a><sup>1</sup></span>
                </center>
                </td>
                    <td align="center" width="25%">
              <center>
                <span style="font-size:20px"><a href="http://niessnerlab.org/members/matthias_niessner/profile.html">Matthias Nie&szligner</a><sup>1</sup></span>
                </center>
                
            </tr>
        </tbody></table>

          <table align="center" width="80%">
            <tbody><tr>
                    
                    <td align="center" width="100%">
              <center>
                    <span style="font-size:20px"><sup>1</sup>Visual Computing Lab <br>Technical University of Munich <br> Germany</span>
                </center>
                </td>
                   
        </tr></tbody></table>

          <table align="center" width="80%">
            <tbody><tr>

                    <td align="center" width="200px">
              <center>
                <br>
                <a href="https://github.com/shivangi-aneja/DDT" class="btn btn-primary btn-lg disabled" role="button" aria-pressed="true" aria-disabled="true">[GitHub]</a>
                </center>
                </td>
                    <td align="center" width="200px">
              <center>
                <br>
                <a href="https://arxiv.org/abs/2006.11863" class="btn btn-primary btn-lg active" role="button" aria-pressed="true">[Paper]</a>
                </center>
                </td>

        </tr></tbody></table>
          </center>
        <br>
        
      <hr>

        <center><h2>Abstract</h2></center>
        We propose Deep Distribution Transfer (DDT), a new transfer learning approach to address the problem of zero and few-shot transfer in the context of facial forgery detection. We examine how well a model (pre-)trained with one forgery creation method generalizes towards a previously unseen manipulation technique or different dataset. To facilitate this transfer, we introduce a new mixture model-based loss formulation that learns a multi-modal distribution, with modes corresponding to class categories of the underlying data of the source forgery method. Our core idea is to first pre-train an encoder neural network, which maps each mode of this distribution to the respective class labels, i.e., real or fake images in the source domain by minimizing wasserstein distance between them. In order to transfer this model to a new domain, we associate a few target samples with one of the previously trained modes. In addition, we propose a spatial mixup augmentation strategy that further helps generalization across domains. We find this learning strategy to be surprisingly effective at domain transfer compared to a traditional classification or even state-of-the-art domain adaptation/few-shot learning methods. For instance, compared to the best baseline, our method improves the classification accuracy by 4.88% for zero-shot and by 8.38% for the few-shot case transferred from the FaceForensics++ to Dessa dataset. <br>

    <br>
      
      <hr>
      <center><h2>Method Overview</h2></center>
      <table align="center" width="100%">
          <tbody><tr>
                  <td width="400px">
            <center>
                      <img class="rounded" src="./images/teaser.jpg" width="100%">
            </center>
                  </td>
                  </tr>
                  </tbody></table>
            <br>
            
            (a) Pre-training: $\theta$ encodes samples from the source domain into a latent distribution $q({z}_i|{x}_i)$. ${\epsilon}_c$ then maps class labels $c$ to the encoded distributions of the prototype multi-modal distribution ${\varepsilon}$.
            (b) Fine-tuning: the pre-trained encoder ${\theta}$ is used to map the few-shot samples from the target dataset with the same prototype multi-modal distribution ${\varepsilon}$, which learns a common subspace between samples across domains. 
            (c) Test-time: a test sample ${x}_{test}$ is encoded into the latent distribution $q({z}_{test}|{x}_{test})$ by using the pre-trained encoder ${\theta}$. We then compute the distance of the latent code with respect to all components of the distribution, and assign a class label based on the component it is closest to.
            <br>
          <br>
      
    <hr>

      <!-- <div class="disclaimerbox"> -->

         <!-- <span style="color:#646464"> -->
           
           <center><h2>Datasets</h2></center>
            <!-- <center><span style="font-size:28px"><b>Datasets</b></span></center> -->

            <br>

       Since our goal is to generalize across datasets and methods, we experimented on datasets with sufficient diversity. Please contact the corresponding authors to get access to the datasets. However, the AIF datasets is donated by <a href='https://aifoundation.com/'>AI Foundation</a> to us and can be downloaded <a href='https://www.dropbox.com/s/arnx7s13hm129ra/AIF.zip'>here</a>. 
      

     
    <div class="Column"><div class="card" >
                  <img class="card-img-top" src="images/Images.jpg" alt="Card image cap" style="height: 45%">
                  <div class="card-body">
                    <center>
                    <table align="center" width="100%">
                                <tbody><tr>

                                  <td align="center" width="20%">
                                  <center>
                                    <br>
                                    <a href="https://arxiv.org/abs/1901.08971" class="btn btn-primary" role="button" aria-pressed="true">FaceForensics++</a>
                                    </center>
                                    </td>

                                  <td align="center" width="20%">
                                  <center>
                                    <br>
                                    <a href="https://ai.googleblog.com/2019/09/contributing-data-to-deepfake-detection.html" class="btn btn-primary" role="button" aria-pressed="true">Google DFD</a>
                                    </center>
                                    </td>

                                  <td align="center" width="20%">
                                  <center>
                                    <br>
                                    <a href="https://github.com/dessa-oss/DeepFake-Detection" class="btn btn-primary" role="button" aria-pressed="true">Dessa</a>
                                    </center>
                                    </td>

                                  <td align="center" width="20%">
                                  <center>
                                    <br>
                                    <a href="https://arxiv.org/pdf/1909.12962.pdf" class="btn btn-primary" role="button" aria-pressed="true">Celeb DF</a>
                                    </center>
                                    </td>

                                  <td align="center" width="20%">
                                  <center>
                                    <br>
                                    <a href="https://www.dropbox.com/s/arnx7s13hm129ra/AIF.zip" class="btn btn-primary" role="button" aria-pressed="true">AIF</a>
                                    </center>
                                    </td>

                                  

                            </tr></tbody></table>


                    </center>
                  
                  </div>
                </div>
    </div>
    <br>
    Figure shows sample frames from the datasets used for evaluation of our experiments. The top row shows the frames from the real videos and bottom row shows the frames from the corresponding fake videos for paired datasets (FaceForensics++ and Google DFD) and randomly selected videos for unpaired datasets (Dessa, AIF, and Celeb DF). For FaceForensics++, the frames from DF manipulation method are shown.
    <hr>

    <center><h2>Results</h2></center>
        <div class="Column"><div class="card" >
                  <img class="card-img-top" src="images/zero_shot.png" alt="Card image cap" style="height: 55%">
                  <div class="card-body">
                    <center>
                    Zero-shot classification accuracy from FF++ to four other datasets: although there is a significant shift in domains (e.g., Google DFDC and Dessa contain mostly frontal faces in contrast to AIF which varies much more in pose and lightning), our method achieves  transfer performance significantly higher than all baselines (last column).


                    </center>
                  
                  </div>
                </div>
    </div>
      
      <br>
      
    <div class="Column"><div class="card" >
                    <img class="card-img-top" src="images/few_shot_aif.jpg" alt="Card image cap" style="height: 35%">
                    <img class="card-img-top" src="images/few_shot_dessa.jpg" alt="Card image cap" style="height: 35%">
                    <img class="card-img-top" src="images/few_shot_celeb.jpg" alt="Card image cap" style="height: 35%">
                    <img class="card-img-top" src="images/legends_flat.jpg" alt="Card image cap" style="height: 40%">
                  <div class="card-body">
                    <center>
                    Few-shot transfer from FF++ to three other datasets. Our method outperforms all the other approaches giving 70.32%, 84.80%, 77.07% accuracy for AIF, Dessa and Celeb DF dataset, respectively after fine-tuning with only 100 images.


                    </center>
                  
                  </div>
                </div>
      </div>
      
      
      

    <br>


      <hr>
        <center><h2>Paper</h2></center><table align="center" width="700" px="">

          <tbody><tr>
          <td><a href="https://arxiv.org/abs/2006.11863"><img class="layered-paper-big" style="height:175px" src="./images/paper.jpg"></a></td>
          <td><span style="font-size:12pt">S. Aneja, M. Nie&szligner.</span><br>
          <b><span style="font-size:12pt">Generalized Zero and Few-Shot Transfer for Facial Forgery Detection</span></b><br>
          <span style="font-size:12pt"> (<a href="https://arxiv.org/abs/2006.11863">Paper</a>)</span>
          </td>

          <br>
          <table align="center" width="600px">
            <tbody>
              <tr>
                <td>
                  <center>
                    <span style="font-size:22px">
                      <a href="./bibtex.txt" target="_blank">[Bibtex]</a>
                    </span>
                  </center>
                </td>
              </tr>
            </tbody>
          </table>
      <br>

      <br><hr>


        <table align="center" width="100%">
          <tbody><tr>
                  <td width="400px">
            <left>
          <center><h2>Acknowledgements</h2></center>
          We gratefully acknowledge the support of this research by the AI Foundation, a TUM-IAS Rudolf MÃ¶&szligbauer Fellowship, the ERC Starting Grant Scan2CAD (804724), and Google Faculty Award. Website template inspired from <a href="https://richzhang.github.io/colorization/">Colorful Colorization</a>
      </left>
    </td>
       </tr>
    </tbody></table>

    <br><br>


<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-75863369-7"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-75863369-7');
</script>


</body></html>
